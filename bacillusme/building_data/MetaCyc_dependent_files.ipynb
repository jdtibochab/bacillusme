{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate MetaCyc-dependendt files\n",
    "\n",
    "NOTE: RUN generate_flatfiles AGAIN AFTER MAKING CHANGES TO THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_complexes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn on pathway tools. Go to pathway tools directory ('/opt/pathway-tools') and run ./pathway-tools -lisp -python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cobra\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import pythoncyc as pc\n",
    "import re\n",
    "from Bio.SeqUtils import seq3\n",
    "from Bio import Seq\n",
    "from os.path import join\n",
    "\n",
    "## Metabolites\n",
    "\n",
    "met_output_file = 'metabolites.txt'\n",
    "\n",
    "# Define Models\n",
    "directory = '/home/jt/UCSD/bacillusme-master/bacillusme/building_data/'\n",
    "eco_directory = join(directory, 'iJO1366.json')\n",
    "ijo_directory = join(directory, 'iYO844.json')\n",
    "uni_directory = join(directory, 'universal_model.json')\n",
    "\n",
    "eco = cobra.io.load_json_model(eco_directory)\n",
    "m_model = cobra.io.load_json_model(ijo_directory)\n",
    "uni = cobra.io.load_json_model(uni_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Solution 0.12 at 0x7f14bbf73350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove reactions\n",
    "remove_reactions = ['ETOHt3' # There is no evidence of ethanol being actively transported\n",
    "                   ]\n",
    "\n",
    "for rxn_id in remove_reactions:\n",
    "    rxn = m_model.reactions.get_by_id(rxn_id)\n",
    "    rxn.remove_from_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atp_c + cu_e + h2o_c --> adp_c + cu_c + h_c + pi_c\n",
      "atp_c + cu2_e + h2o_c --> adp_c + cu2_c + h_c + pi_c\n",
      "cobalt2_e --> cobalt2_c\n",
      "etoh_e --> etoh_c\n"
     ]
    }
   ],
   "source": [
    "## Copper transport fixes\n",
    "cu_c = cobra.Metabolite('cu_c')\n",
    "cu_e = cobra.Metabolite('cu_e')\n",
    "m_model.add_metabolites([cu_c,cu_e])\n",
    "\n",
    "# CUt1 is for Cu+1 (BSU33500)\n",
    "r = m_model.reactions.Cut1\n",
    "r.subtract_metabolites({cobra.Metabolite('cu2_c'):-1,cobra.Metabolite('cu2_e'):1})\n",
    "r.add_metabolites({'cu_e':-1,'cu_c':1})\n",
    "print(r.reaction)\n",
    "\n",
    "# Cu2abc1 is for Cu+2(BSU33490)\n",
    "r = cobra.Reaction('CU2abc1')\n",
    "m_model.add_reaction(r)\n",
    "r.add_metabolites({'atp_c':-1,'cu2_e':-1,'h2o_c':-1,\n",
    "                   'adp_c':1,'cu2_c':1,'h_c':1,'pi_c':1})\n",
    "r.gene_reaction_rule = 'BSU33500'\n",
    "print(r.reaction)\n",
    "\n",
    "# Cobalt(II) import through permease\n",
    "r = cobra.Reaction('COBALTt5')\n",
    "m_model.add_reaction(r)\n",
    "r.add_metabolites({'cobalt2_e':-1,'cobalt2_c':1})\n",
    "r.name = 'Cobalt(II) transport via diffusion'\n",
    "r.gene_reaction_rule = ''\n",
    "print(r.reaction)\n",
    "\n",
    "# Arginine is transported through permeases and ABC transporters, not proton symport\n",
    "r = m_model.reactions.ARGPt6\n",
    "r.remove_from_model()\n",
    "\n",
    "# Ethanol diffuses through membrane\n",
    "r = cobra.Reaction('ETOHtex')\n",
    "m_model.add_reaction(r)\n",
    "r.add_metabolites({'etoh_e':-1,'etoh_c':1})\n",
    "r.name = 'Ethanol transport via diffusion'\n",
    "r.gene_reaction_rule = ''\n",
    "print(r.reaction)\n",
    "\n",
    "\n",
    "## Chloride-Potassium transport through BSU31100. Not necessary as cl is not used by the model.\n",
    "\n",
    "## Thiamine (vitamin B2) transport fixes\n",
    "# r = cobra.Reaction('THMabc')\n",
    "# m_model.add_reaction(r)\n",
    "# r.add_metabolites({'atp_c':-1,'cu2_e':-1,'h2o_c':-1,\n",
    "#                    'adp_c':1,'cu2_c':1,'h_c':1,'pi_c':1})\n",
    "# r.gene_reaction_rule = 'BSU33490'\n",
    "# print(r.reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown metabolite 'cbl1_e' created\n",
      "unknown metabolite 'cbl1_c' created\n"
     ]
    }
   ],
   "source": [
    "## New transporters\n",
    "new_reactions_dict = {\n",
    "    'CBLtex':'cbl1_e -> cbl1_c',\n",
    "    'EX_cbl1_e':'cbl1_e <=>'\n",
    "}\n",
    "\n",
    "for rxn_id in new_reactions_dict.keys():\n",
    "    rxn = cobra.Reaction(rxn_id)\n",
    "    m_model.add_reaction(rxn)\n",
    "    rxn.build_reaction_from_string(new_reactions_dict[rxn_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Fix of gene reaction rules\n",
    "new_rules_dict = {\n",
    "    ## BsubCyc\n",
    "    'ACTD2' : 'BSU08060 and BSU08070',\n",
    "    'AIRC1' : 'BSU06420 or BSU06430',\n",
    "    'ANS' : 'BSU00750 or BSU22680',\n",
    "    'PRFGS_1' : 'BSU06480 or BSU06470',\n",
    "    'RNDR1' : 'BSU17380 and BSU17390',\n",
    "    'RNDR2' : 'BSU17380 and BSU17390',\n",
    "    'RNDR3' : 'BSU17380 and BSU17390',\n",
    "    'RNDR4' : 'BSU17380 and BSU17390',\n",
    "    'LYSLG_BS' : '', # Former rule BG12900 of inexistent gene\n",
    "    'PNTOt2': '', # Former rule BSU38240 is a putative Acetate/Na symporter\n",
    "    'Kt3r':'BSU31610 and BSU31660 and BSU31600 and BSU31620 and BSU31630 and BSU31650 and BSU31640', # Rule is OR, but it should be AND. CPL8J2-158\n",
    "    'NAt3_1':'BSU31600 and BSU31610 and BSU31620 and BSU31630 and BSU31640 and BSU31650 and BSU31660 or BSU09680 or BSU33420 or BSU11640 or BSU09850',\n",
    "    \n",
    "    ## From BLAST\n",
    "    'HCO3E' : 'BSU30690',\n",
    "    'PGL':'BSU13010',\n",
    "    \n",
    "    ## TransportDB\n",
    "    'F6Pt6_2':'BSU12010 or BSU14400',\n",
    "    'ACt2r' : 'BSU38240',\n",
    "    \n",
    "    ## New transporters from BsubCyc\n",
    "    'CBLtex':'BSU33170',\n",
    "    'ASPt2r':'BSU10220',\n",
    "#     'PSER_Lt6':'BSU19999', # This one comes from DELTA-BLAST the human protein to bacillus (?)\n",
    "    'MAN6Pt6':'BSU10520',\n",
    "    'PYRt2':'BSU28900 and BSU28910',\n",
    "    'GLCpts':'BSU13890 or (BSU38570 and BSU38580 and BSU38590)',\n",
    "    'RIBFLVt2':'BSU23050'\n",
    "    \n",
    "}\n",
    "pd.DataFrame.from_dict({'rule':new_rules_dict}).to_csv('new_rules.csv')\n",
    "for rxn_id in new_rules_dict.keys():\n",
    "    m_model.reactions.get_by_id(rxn_id).gene_reaction_rule = new_rules_dict[rxn_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACTD2</th>\n",
       "      <td>BSU08060 and BSU08070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACt2r</th>\n",
       "      <td>BSU38240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRC1</th>\n",
       "      <td>BSU06420 or BSU06430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANS</th>\n",
       "      <td>BSU00750 or BSU22680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPt2r</th>\n",
       "      <td>BSU10220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBLtex</th>\n",
       "      <td>BSU33170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F6Pt6_2</th>\n",
       "      <td>BSU12010 or BSU14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLCpts</th>\n",
       "      <td>BSU13890 or (BSU38570 and BSU38580 and BSU38590)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCO3E</th>\n",
       "      <td>BSU30690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kt3r</th>\n",
       "      <td>BSU31610 and BSU31660 and BSU31600 and BSU3162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LYSLG_BS</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAN6Pt6</th>\n",
       "      <td>BSU10520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAt3_1</th>\n",
       "      <td>BSU31600 and BSU31610 and BSU31620 and BSU3163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGL</th>\n",
       "      <td>BSU13010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNTOt2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRFGS_1</th>\n",
       "      <td>BSU06480 or BSU06470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PYRt2</th>\n",
       "      <td>BSU28900 and BSU28910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIBFLVt2</th>\n",
       "      <td>BSU23050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNDR1</th>\n",
       "      <td>BSU17380 and BSU17390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNDR2</th>\n",
       "      <td>BSU17380 and BSU17390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNDR3</th>\n",
       "      <td>BSU17380 and BSU17390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNDR4</th>\n",
       "      <td>BSU17380 and BSU17390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       rule\n",
       "ACTD2                                 BSU08060 and BSU08070\n",
       "ACt2r                                              BSU38240\n",
       "AIRC1                                  BSU06420 or BSU06430\n",
       "ANS                                    BSU00750 or BSU22680\n",
       "ASPt2r                                             BSU10220\n",
       "CBLtex                                             BSU33170\n",
       "F6Pt6_2                                BSU12010 or BSU14400\n",
       "GLCpts     BSU13890 or (BSU38570 and BSU38580 and BSU38590)\n",
       "HCO3E                                              BSU30690\n",
       "Kt3r      BSU31610 and BSU31660 and BSU31600 and BSU3162...\n",
       "LYSLG_BS                                                   \n",
       "MAN6Pt6                                            BSU10520\n",
       "NAt3_1    BSU31600 and BSU31610 and BSU31620 and BSU3163...\n",
       "PGL                                                BSU13010\n",
       "PNTOt2                                                     \n",
       "PRFGS_1                                BSU06480 or BSU06470\n",
       "PYRt2                                 BSU28900 and BSU28910\n",
       "RIBFLVt2                                           BSU23050\n",
       "RNDR1                                 BSU17380 and BSU17390\n",
       "RNDR2                                 BSU17380 and BSU17390\n",
       "RNDR3                                 BSU17380 and BSU17390\n",
       "RNDR4                                 BSU17380 and BSU17390"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict({'rule':new_rules_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def frameid_to_str(frameid):\n",
    "    string = str(frameid)\n",
    "    string = string.replace('|','')\n",
    "    if '_MISC_' in string:\n",
    "        string = string.replace('_MISC_','_misc_') # GenBank and BsubCyc use different cases.\n",
    "    return string\n",
    "\n",
    "def frames_to_strlist(frames):\n",
    "    strlist = []\n",
    "    for instance in frames:\n",
    "        strlist.append(frameid_to_str(instance.frameid))\n",
    "    return strlist\n",
    "        \n",
    "def generate_prot_cplx_dict(DB):\n",
    "    PROTEINS = DB.proteins\n",
    "    protein_complexes_dict = dict()\n",
    "    for cplx in PROTEINS.instances:\n",
    "        cplx_string = frameid_to_str(cplx.frameid)\n",
    "        genes_of_cplx = pc.PGDB.genes_of_protein(DB,cplx)\n",
    "        if genes_of_cplx:\n",
    "            for gene in genes_of_cplx:\n",
    "                gene_string = frameid_to_str(gene)                    \n",
    "                if cplx_string not in protein_complexes_dict.keys():\n",
    "                    protein_complexes_dict[cplx_string] = []\n",
    "                protein_complexes_dict[cplx_string].append(gene_string)\n",
    "    return protein_complexes_dict\n",
    "\n",
    "def generate_id_to_accession_dict(DB):\n",
    "    gene_id_dict = dict()\n",
    "    GENES = DB.genes\n",
    "    for gene in GENES.instances:\n",
    "        gene_data = pc.PToolsFrame.PFrame.get_frame_data(gene)\n",
    "        gene_id = frameid_to_str(gene.frameid)\n",
    "        gene_id_dict[gene_id] = str(gene_data.accession_1)\n",
    "    return gene_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsub = pc.select_organism('bsub')\n",
    "ecoli = pc.select_organism('ecoli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PROTEINS = bsub.proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "protein_complexes_dict = generate_prot_cplx_dict(bsub)\n",
    "ecoli_protein_complexes_dict = generate_prot_cplx_dict(ecoli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## MANUALLY ADDED COMPLEXES\n",
    "protein_complexes_dict['secYEG'] = ['BSU01360','BSU01000','BSU33630']\n",
    "protein_complexes_dict['SRP-CPLX'] = ['BSU15980','BSU_misc_RNA_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_id_dict = generate_id_to_accession_dict(ecoli)\n",
    "ecoli_gene_to_cplx_dict = dict()\n",
    "for cplx_id in ecoli_protein_complexes_dict.keys():\n",
    "    old_values = ecoli_protein_complexes_dict[cplx_id]\n",
    "    new_values = []\n",
    "    for old_value in old_values:\n",
    "        try:\n",
    "            new_values.append(gene_id_dict[old_value])\n",
    "        except:\n",
    "            continue\n",
    "    for new_value in new_values:\n",
    "        if new_value not in ecoli_gene_to_cplx_dict.keys():\n",
    "            ecoli_gene_to_cplx_dict[new_value] = cplx_id\n",
    "    ecoli_protein_complexes_dict[cplx_id] = new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get stoichiometry from homology with ECOLI\n",
    "ecoli_blast_df = pd.read_csv('blast_out_bsub_as_ref.txt', sep='\\t')\n",
    "\n",
    "bsub_to_ecoli_dict = dict()\n",
    "ecoli_to_bsub_dict = dict()\n",
    "for key, row in ecoli_blast_df.iterrows():\n",
    "    if row['ident'] > 0.2:\n",
    "        bsub_id = row['BSUB_gene']\n",
    "        ecoli_id = row['ECOLI_gene']\n",
    "        bsub_to_ecoli_dict[bsub_id] = ecoli_id\n",
    "        ecoli_to_bsub_dict[ecoli_id] = bsub_id\n",
    "# BLAST might have found false positive gene hits.\n",
    "# However, stoichiometry is only used if proteins in complex are the same as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get stoichiometry information from ECOLI\n",
    "ecoli_stoich_df = pd.read_csv('ecoli_protein_complexes.txt', sep='\\t',\n",
    "                              names=['Complex', 'Name', 'Stoichiometry',\n",
    "                                 'Source'])\n",
    "ecoli_stoich_dict = dict()\n",
    "for key, row in ecoli_stoich_df.iterrows():\n",
    "    cplx_id = row['Complex']\n",
    "    ecoli_stoich_dict[cplx_id] = []\n",
    "    stoichiometry_dict = dict()\n",
    "    for bnums in row['Stoichiometry'].split(' AND '):\n",
    "        bnum, num = bnums.rstrip(')').split('(')\n",
    "        stoichiometry = float(num) if not num == '' else 1.\n",
    "        stoichiometry_dict[bnum] = stoichiometry\n",
    "        ecoli_stoich_dict[cplx_id] = stoichiometry_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get possible complex homolog in ecoli\n",
    "cplx_to_cplx_dict = dict()\n",
    "\n",
    "for cplx_id in protein_complexes_dict.keys():\n",
    "    gene_ids = protein_complexes_dict[cplx_id]\n",
    "    \n",
    "    for gene_id in gene_ids:\n",
    "        try:\n",
    "            ecoli_gene = bsub_to_ecoli_dict[gene_id]\n",
    "            ecoli_cplx = ecoli_gene_to_cplx_dict[ecoli_gene]\n",
    "            \n",
    "            ecoli_cplx_genes = ecoli_protein_complexes_dict[ecoli_cplx]\n",
    "            \n",
    "            if len(ecoli_cplx_genes) == len(gene_ids):\n",
    "                converted_bsub_genes = []\n",
    "                for cplx_gene in gene_ids:\n",
    "                    converted_bsub_genes.append(bsub_to_ecoli_dict[cplx_gene])\n",
    "                if len(set(ecoli_cplx_genes) & set(converted_bsub_genes)) == len(ecoli_cplx_genes):\n",
    "                    cplx_to_cplx_dict[cplx_id] = ecoli_cplx\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create stoichiometry\n",
    "bsub_stoich_dict = dict()\n",
    "complexes_not_included = []\n",
    "for cplx in protein_complexes_dict.keys():\n",
    "    if cplx in cplx_to_cplx_dict.keys():\n",
    "        ecoli_cplx = cplx_to_cplx_dict[cplx]\n",
    "        try:\n",
    "            ecoli_cplx_stoich_dict = ecoli_stoich_dict[ecoli_cplx]\n",
    "            bsub_cplx_stoich_dict = dict()\n",
    "            for gene_of_ecoli_cplx in ecoli_cplx_stoich_dict.keys():\n",
    "                bsub_gene_id = ecoli_to_bsub_dict[gene_of_ecoli_cplx]\n",
    "                bsub_cplx_stoich_dict[bsub_gene_id] = ecoli_cplx_stoich_dict[gene_of_ecoli_cplx]\n",
    "            bsub_stoich_dict[cplx] = bsub_cplx_stoich_dict\n",
    "        except:\n",
    "            complexes_not_included.append(ecoli_cplx)\n",
    "print 'A total of ' + str(len(complexes_not_included)) + ' ecoli complexes were not included'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add bsubcyc complex stoichiometry here and correct bsub_stoich_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gene_dictionary.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_to_locus_dict = dict()\n",
    "GENES = bsub.genes\n",
    "for gene in GENES.instances:\n",
    "    gene_data = pc.PToolsFrame.PFrame.get_frame_data(gene)\n",
    "    gene_id = frameid_to_str(gene.frameid)\n",
    "    \n",
    "    name = str(gene_data.common_name)\n",
    "    name_to_locus_dict[name] = gene_id\n",
    "    if not gene_data.synonyms:\n",
    "        continue\n",
    "    for syn in gene_data.synonyms:\n",
    "        syn_id = frameid_to_str(syn)\n",
    "        name_to_locus_dict[syn_id] = gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_dictionary = pd.DataFrame.from_dict({'locus_id':name_to_locus_dict})\n",
    "gene_dictionary.index.name = 'name'\n",
    "gene_dictionary.to_csv('gene_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bsub_enzyme_stoichiometry.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from HTMLParser import HTMLParser\n",
    "import urllib2\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "gene_dictionary = pd.read_csv('gene_name_dictionary.csv',index_col=1)\n",
    "# Just read, but run again if needed (takes 1 hour or more)\n",
    "bsubcyc_complex_stoichiometry_dict = json.loads(open(\"bsub_enzyme_stoichiometry.txt\",\"r\").read() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Just read, but uncomment if needed (takes 1 hour or more)\n",
    "# protein_html ='https://bsubcyc.org/BSUB/NEW-IMAGE?type=ENZYME&object={}'\n",
    "# bsubcyc_complex_stoichiometry_dict = dict()\n",
    "# for protein_id in tqdm(protein_complexes_dict.keys()):\n",
    "# #protein_id = 'CPLX8J2-59'\n",
    "#     # Get HTML\n",
    "#     try:\n",
    "#         html_page = urllib2.urlopen(protein_html.format(protein_id))\n",
    "#     except:\n",
    "#         # No HTML\n",
    "#         continue\n",
    "#     soup = BeautifulSoup(html_page)\n",
    "\n",
    "#     # Parse HTML\n",
    "#     try:\n",
    "#         raw_string = soup.findAll('a',attrs={'href':'/BSUB/NEW-IMAGE?type=POLYPEPTIDE&object={}'.format(protein_id)})[0]\n",
    "#     except:\n",
    "#         # Different format\n",
    "#         try:\n",
    "#             raw_string = soup.findAll('a',attrs={'class':'ENZYME'})[0]\n",
    "#         except:\n",
    "#             # No HTML\n",
    "#             continue\n",
    "#     raw_string = str(raw_string)\n",
    "#     stoich_raw_string = raw_string.split('\"')[-1].split('=  ')[-1]\n",
    "\n",
    "#     # Create dictionary\n",
    "#     subcomplex_list = stoich_raw_string.split('][')\n",
    "#     bsubcyc_complex_stoichiometry_dict[protein_id] = dict()\n",
    "#     for subcplx in subcomplex_list:\n",
    "#         subcplx_raw_string = subcplx.replace('[','').replace(']','').replace('(','').replace(')','')\n",
    "#         if '<sub>' in subcplx_raw_string:\n",
    "#             split_string = subcplx_raw_string.replace('<sub>',',').replace('</sub>',',').split(',')[:-1]\n",
    "#             for idx,el in enumerate(split_string):\n",
    "#                 if (idx+1)%2:\n",
    "#                     gene = split_string[idx]\n",
    "#                     stoich = split_string[idx+1]\n",
    "#                     if gene:\n",
    "#                         gene = gene.replace(gene[0],gene[0].lower())\n",
    "#                         if gene in gene_dictionary.index:\n",
    "#                             locus_id = gene_dictionary.loc[gene]['locus_id']\n",
    "#                             bsubcyc_complex_stoichiometry_dict[protein_id][locus_id] = stoich\n",
    "#                         else:\n",
    "#                             print(gene, ' not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# bsubcyc_complex_stoichiometry_dict\n",
    "# with open ('bsub_enzyme_stoichiometry.txt','w') as file:\n",
    "#     file.write(json.dumps(bsubcyc_complex_stoichiometry_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'protein_complexes.txt'\n",
    "file = open(filename,'w')\n",
    "CPLX_list = []\n",
    "genes_all_cplxs = []\n",
    "\n",
    "for cplx in protein_complexes_dict:\n",
    "    cplx_string = cplx\n",
    "    string = cplx_string + '\\t' + 'default_name' + '\\t'\n",
    "    try:\n",
    "        genes_of_cplx = protein_complexes_dict[cplx]\n",
    "    except:\n",
    "        genes_of_cplx = []\n",
    "    if genes_of_cplx:\n",
    "        for gene_id in genes_of_cplx:\n",
    "            # If gene info is in bsubcyc\n",
    "            if cplx_string in bsubcyc_complex_stoichiometry_dict.keys() and \\\n",
    "                        gene_id in bsubcyc_complex_stoichiometry_dict[cplx_string].keys():\n",
    "                stoich = bsubcyc_complex_stoichiometry_dict[cplx_string][gene_id]\n",
    "            # If not, use information from ecoli\n",
    "            else:\n",
    "                try:\n",
    "                    stoich = str(int(bsub_stoich_dict[cplx_string][gene_id]))\n",
    "                except:\n",
    "                    stoich = ''\n",
    "            string = string + gene_id + '(' + stoich + ')' + ' AND '\n",
    "        string = string[0:len(string)-5]\n",
    "        string = string + '\\t' + 'M_protein_recon' + '\\n'\n",
    "        \n",
    "        file.write(string)\n",
    "\n",
    "        CPLX_list.append(cplx_string)\n",
    "    genes_all_cplxs.append(genes_of_cplx)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## protein_modification.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "ref_filename = 'ecoli_protein_modification.txt'\n",
    "complex_mods = pandas.read_table(ref_filename)\n",
    "complex_mods = complex_mods.set_index('Modified_enzyme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from six import iteritems\n",
    "new_mod_dict = {}\n",
    "for key, value in iteritems(complex_mods.T.to_dict()):\n",
    "    if key.startswith('#'):\n",
    "            continue\n",
    "    key = key.replace('_DASH_', '__')\n",
    "    \n",
    "    protein_name = value['Core_enzyme']\n",
    "    new_mod_dict[protein_name] = {}\n",
    "    new_mod_dict[protein_name]['modifications'] = {}\n",
    "    for mods in value['Modifications'].split(' AND '):\n",
    "        mod, num_mods = mods.rstrip(')').split('(')\n",
    "        if num_mods == '':\n",
    "            num_mods = 1.\n",
    "        else:\n",
    "            num_mods = float(num_mods)\n",
    "\n",
    "        mod = mod.replace('_DASH_', '__')\n",
    "        new_mod_dict[protein_name]['modifications'][mod] = num_mods\n",
    "ecoli_mod_dict = new_mod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'protein_modification.txt'\n",
    "file = open(filename,'w')\n",
    "file.write('Modified_enzyme' + '\\t' + 'Core_enzyme' + '\\t' + 'Modifications' + '\\t' + 'Source' + '\\n')\n",
    "\n",
    "cplx_cofactor_dict = dict()\n",
    "cplx_cofactor_dict = {}\n",
    "for cplx in protein_complexes_dict.keys():\n",
    "    if cplx in cplx_to_cplx_dict.keys():\n",
    "        try:\n",
    "            cplx_cofactor_dict[cplx] = ecoli_mod_dict[cplx_to_cplx_dict[cplx]]['modifications']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "for cplx in cplx_cofactor_dict.keys():\n",
    "    cofactor_string = ''\n",
    "    mod_string = ''\n",
    "    for cofactor in cplx_cofactor_dict[cplx].keys():\n",
    "        stoich = str(int(cplx_cofactor_dict[cplx][cofactor]))\n",
    "        stoich_string = stoich\n",
    "        if stoich == '1':\n",
    "            stoich_string = ''\n",
    "        cofactor_string = cofactor_string + cofactor + '(' + stoich_string + ')' + ' AND '\n",
    "        \n",
    "        if stoich == '1':\n",
    "            mod_string = mod_string + '_mod_' + stoich_string + cofactor\n",
    "        else:\n",
    "            mod_string = mod_string + '_mod_' + stoich_string + ':' + cofactor\n",
    "    cofactor_string = cofactor_string[0:len(cofactor_string)-5]\n",
    "    \n",
    "    string = cplx + mod_string +'\\t' + cplx + '\\t' + cofactor_string + '\\t' + 'M_protein_recon' + '\\n'\n",
    "    \n",
    "    file.write(string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Fe-S transfer\n",
    "filename = 'protein_modification.txt'\n",
    "file = open(filename,'a')\n",
    "\n",
    "string = 'BSU32680-MONOMER_mod_1:2fe2s' +'\\t' + 'BSU32680-MONOMER' + '\\t' + \\\n",
    "            '2fe2s(1)' + '\\t' + 'M_protein_recon' + '\\n'\n",
    "file.write(string)\n",
    "\n",
    "string = 'BSU32680-MONOMER_mod_1:4fe4s' +'\\t' + 'BSU32680-MONOMER' + '\\t' + \\\n",
    "            '4fe4s(1)' + '\\t' + 'M_protein_recon' + '\\n'\n",
    "file.write(string)\n",
    "\n",
    "## M-model complexes\n",
    "string = 'BSU15920-MONOMER_mod_pan4p' +'\\t' + 'BSU15920-MONOMER' + '\\t' + \\\n",
    "            'pan4p()' + '\\t' + 'M_protein_recon' + '\\n'\n",
    "file.write(string)\n",
    "\n",
    "#string = 'BSU28500-MONOMER_mod_Oxidized' +'\\t' + 'BSU28500-MONOMER' + '\\t' + \\\n",
    "#            'Oxidized()' + '\\t' + 'M_protein_recon' + '\\n'\n",
    "#file.write(string)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enzyme_reaction_association.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'enzyme_reaction_association.txt'\n",
    "prot_cplx_filename = 'protein_complexes.txt'\n",
    "\n",
    "file = open(filename,'w')\n",
    "prot_cplx_file = open(prot_cplx_filename,'a')\n",
    "\n",
    "standard_gene_length = 8\n",
    "\n",
    "enz_rxn_assoc_list = []\n",
    "artificial_cplxs = []\n",
    "artificial_id = 0;\n",
    "\n",
    "enz_rxn_assoc_dict = dict()\n",
    "\n",
    "for reaction in m_model.reactions:\n",
    "    if not (reaction.id[0:3] == 'EX_') and not (reaction.id[0:3] == 'DM_'):\n",
    "        # Skip empty rules, these reactions are assigned to CPLX_dummy\n",
    "        if not reaction.gene_reaction_rule:\n",
    "            continue\n",
    "            \n",
    "        string = str(reaction.id) + '\\t' \n",
    "\n",
    "        rule_string = str(reaction.gene_reaction_rule)\n",
    "            \n",
    "        if rule_string:\n",
    "            rule_string = rule_string.replace('(','')\n",
    "            rule_string = rule_string.replace(')','')\n",
    "            rule_list = rule_string.split(' or ')\n",
    "            enz_rxn_assoc = []\n",
    "\n",
    "            reaction_cplx_list = []\n",
    "            for rule in rule_list:\n",
    "                rule_gene_list = rule.split(' and ')\n",
    "                \n",
    "                for index in range(0,len(genes_all_cplxs)-1):\n",
    "                    ref_rule = genes_all_cplxs[index]\n",
    "                    if set(ref_rule) == set(rule_gene_list):\n",
    "                        rule_cplx = CPLX_list[index]\n",
    "                        reaction_cplx_list.append(rule_cplx)\n",
    "\n",
    "            enz_rxn_assoc_list.append(reaction_cplx_list)\n",
    "            string = str(reaction.id) + '\\t'\n",
    "\n",
    "            if reaction_cplx_list:\n",
    "                for cplx in reaction_cplx_list:\n",
    "                    try:\n",
    "                        cplx_id = cplx\n",
    "                        for cofactor in cplx_cofactor_dict[cplx].keys():\n",
    "                            stoich = int(cplx_cofactor_dict[cplx][cofactor])\n",
    "                            if stoich == 1:\n",
    "                                cplx_id = cplx_id + '_mod_' + cofactor\n",
    "                            else:\n",
    "                                cplx_id = cplx_id + '_mod_' + str(stoich) + ':' + cofactor\n",
    "                    except:\n",
    "                        cplx_id = cplx\n",
    "                    string = string + cplx_id + ' OR '\n",
    "            else:\n",
    "                for rule in rule_list:\n",
    "                    stoichiometry_string = ''\n",
    "                    if len(rule) == standard_gene_length:\n",
    "                        artificial_cplx = rule + '-MONOMER'\n",
    "                        stoichiometry_string = rule + '()'\n",
    "                    else:\n",
    "                        artificial_id = artificial_id + 1\n",
    "                        artificial_cplx = 'CPLX000-' + str(artificial_id)\n",
    "                        cplx_gene_list = rule.split(' and ')\n",
    "\n",
    "                        for gene in cplx_gene_list:\n",
    "                            stoichiometry_string = stoichiometry_string + gene + '()' + ' AND '\n",
    "                        stoichiometry_string = stoichiometry_string[0:len(stoichiometry_string)-5]\n",
    "                    string = string + artificial_cplx + ' OR '\n",
    "                    \n",
    "                    if artificial_cplx not in artificial_cplxs:\n",
    "                        artificial_cplxs.append(artificial_cplx)\n",
    "                        prot_cplx_file.write(artificial_cplx + '\\t' + 'default_name' + '\\t' +\n",
    "                                             stoichiometry_string + '\\t' + 'M_protein_recon' + '\\n')\n",
    "            \n",
    "        string = string[0:len(string)-4]\n",
    "        string = string + '\\n'\n",
    "        file.write(string)\n",
    "        \n",
    "        enz_rxn_assoc_dict[cplx_id] = reaction.id\n",
    "    \n",
    "file.close() \n",
    "prot_cplx_file.close()\n",
    "artificial_cplxs = list(set(artificial_cplxs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_cplx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUs_from_bsubcyc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get rho dependence\n",
    "rho_dependent_TUs = []\n",
    "for terminator in bsub.rho_independent_terminators.instances:\n",
    "    terminator_data = pc.PToolsFrame.PFrame.get_frame_data(terminator)\n",
    "    terminator_id = frameid_to_str(terminator.frameid)\n",
    "    TU_list = terminator_data.component_of\n",
    "    \n",
    "    for tu in TU_list:\n",
    "        tu_id = frameid_to_str(tu)\n",
    "        tu_id = tu_id.replace('-','_') \n",
    "        if tu_id not in rho_dependent_TUs:\n",
    "            rho_dependent_TUs.append(tu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get sigma-promoterBOX dict\n",
    "promoterBOX_to_sigma_dict = dict()\n",
    "for sigma in bsub.sigma_factors.instances:\n",
    "    sigma_data = pc.PToolsFrame.PFrame.get_frame_data(sigma)\n",
    "    sigma_id = frameid_to_str(sigma_data.frameid)\n",
    "    promoterBOXes = sigma_data.recognized_promoters\n",
    "    if promoterBOXes:\n",
    "        for promoterBOX in promoterBOXes:\n",
    "            promoterBOX_id = frameid_to_str(promoterBOX)\n",
    "            if promoterBOX_id in promoterBOX_to_sigma_dict.keys():\n",
    "                promoterBOX_to_sigma_dict[promoterBOX_id].append(sigma_id)\n",
    "            else:\n",
    "                promoterBOX_to_sigma_dict[promoterBOX_id] = sigma_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TU_to_sigma_dict = dict()\n",
    "\n",
    "# Get promoter - promoterBOX dict\n",
    "promoter_to_promoterBOX_dict = dict()\n",
    "\n",
    "for promoter in bsub.promoters.instances:\n",
    "    promoter_data = pc.PToolsFrame.PFrame.get_frame_data(promoter)\n",
    "    promoter_id = frameid_to_str(promoter.frameid)\n",
    "    promoterBOXes = promoter_data.promoter_boxes\n",
    "    if promoterBOXes:\n",
    "        promoterBOX = frameid_to_str(promoterBOXes[0])\n",
    "        TUs = promoter_data.component_of\n",
    "        if TUs:\n",
    "            for TU in TUs:\n",
    "                TU_id = frameid_to_str(TU)\n",
    "                TU_id = tu_id = TU_id.replace('-','_') \n",
    "                if TU_id in TU_to_sigma_dict.keys():\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        TU_to_sigma_dict[TU_id] = promoterBOX_to_sigma_dict[promoterBOX]\n",
    "                    except:\n",
    "                        TU_to_sigma_dict[TU_id] = 'BSU25200-MONOMER' # No sigma information, assume RpoD\n",
    "TU_to_sigma_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "filename = 'TUs_from_bsubcyc.txt'\n",
    "file = open(filename,'w')\n",
    "\n",
    "gb_filename = 'NC_000964.gb'   \n",
    "gb_file = SeqIO.read(gb_filename, 'gb')\n",
    "full_seq = str(gb_file.seq)\n",
    "element_types={'CDS', 'rRNA','tRNA', 'ncRNA'}\n",
    "\n",
    "head_string = 'TU_id' + '\\t' + 'start' + '\\t' + 'stop' + '\\t' + 'tss' + '\\t' + 'strand' + '\\t' + 'rho_dependent' + '\\t' + 'sigma' + '\\n'\n",
    "file.write(head_string)\n",
    "TUs = bsub.transcription_units\n",
    "for tu_PFrame in TUs.instances:\n",
    "    tu_data = pc.PToolsFrame.PFrame.get_frame_data(tu_PFrame)\n",
    "    \n",
    "    ## Start and stop\n",
    "    positions = []\n",
    "    for gene_fid in tu_data.components:\n",
    "        if 'BSU' in gene_fid:\n",
    "            gene_PFrame = pc.PToolsFrame.PFrame(gene_fid,bsub,getFrameData=False, isClass=False)\n",
    "            gene_data = pc.PToolsFrame.PFrame.get_frame_data(gene_PFrame)\n",
    "            positions.append(gene_data.left_end_position)\n",
    "            positions.append(gene_data.right_end_position)\n",
    "            gene_id = gene_fid.replace('BSU','BSU_')\n",
    "    if positions:\n",
    "        tu_start = min(positions)\n",
    "        tu_stop = max(positions)\n",
    "    else:\n",
    "        tu_start = 0\n",
    "        tu_stop = 0\n",
    "    \n",
    "    tu_tss = tu_stop\n",
    "\n",
    "    ## ID\n",
    "    tu_id = frameid_to_str(tu_data.frameid)\n",
    "    tu_id = tu_id.replace('-','_')\n",
    "    \n",
    "    ## Sigma\n",
    "    try:\n",
    "        sigma = TU_to_sigma_dict[tu_id]\n",
    "    except:\n",
    "        sigma = 'BSU25200-MONOMER' # No sigma information, assume RpoD\n",
    "    \n",
    "    ## Rho\n",
    "    rho_dependence = 'False' if tu_id in rho_dependent_TUs else 'True'\n",
    "    \n",
    "    ## Strand    \n",
    "    gene_id = gene_id[1:len(gene_id)-1] ## Only use one gene. The others should have the same direction.\n",
    "    for feature in gb_file.features:\n",
    "        if feature.type not in element_types or 'pseudo' in feature.qualifiers:\n",
    "            continue\n",
    "        if feature.qualifiers[\"locus_tag\"][0] == gene_id:\n",
    "            strand = '+' if feature.location.strand == 1 else '-'\n",
    "            \n",
    "    ##\n",
    "    tu_id = tu_id + '_from_' + sigma\n",
    "    string = str(tu_id) + '\\t' + str(tu_start) + '\\t' + str(tu_stop) + '\\t' + str(tu_tss) + '\\t' + str(strand) + '\\t' + rho_dependence + '\\t' + sigma + '\\n'\n",
    "    \n",
    "    file.write(string)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TUs_from_ecocyc.txt',sep='\\t')\n",
    "\n",
    "len(set(df['sigma'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trna_to_codon dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DNA_to_codon_table = {'TTT': 'F',\n",
    " 'TTC': 'F',\n",
    " 'TTA': 'L',\n",
    " 'TTG': 'L',\n",
    " 'TCT': 'S',\n",
    " 'TCC': 'S',\n",
    " 'TCA': 'S',\n",
    " 'TCG': 'S',\n",
    " 'TAT': 'Y',\n",
    " 'TAC': 'Y',\n",
    " 'TAA': '*',\n",
    " 'TAG': '*',\n",
    " 'TGT': 'C',\n",
    " 'TGC': 'C',\n",
    " 'TGA': '*',\n",
    " 'TGG': 'W',\n",
    " 'CTT': 'L',\n",
    " 'CTC': 'L',\n",
    " 'CTA': 'L',\n",
    " 'CTG': 'L',\n",
    " 'CCT': 'P',\n",
    " 'CCC': 'P',\n",
    " 'CCA': 'P',\n",
    " 'CCG': 'P',\n",
    " 'CAT': 'H',\n",
    " 'CAC': 'H',\n",
    " 'CAA': 'Q',\n",
    " 'CAG': 'Q',\n",
    " 'CGT': 'R',\n",
    " 'CGC': 'R',\n",
    " 'CGA': 'R',\n",
    " 'CGG': 'R',\n",
    " 'ATT': 'I',\n",
    " 'ATC': 'I',\n",
    " 'ATA': 'I',\n",
    " 'ATG': 'M',\n",
    " 'ACT': 'T',\n",
    " 'ACC': 'T',\n",
    " 'ACA': 'T',\n",
    " 'ACG': 'T',\n",
    " 'AAT': 'N',\n",
    " 'AAC': 'N',\n",
    " 'AAA': 'K',\n",
    " 'AAG': 'K',\n",
    " 'AGT': 'S',\n",
    " 'AGC': 'S',\n",
    " 'AGA': 'R',\n",
    " 'AGG': 'R',\n",
    " 'GTT': 'V',\n",
    " 'GTC': 'V',\n",
    " 'GTA': 'V',\n",
    " 'GTG': 'V',\n",
    " 'GCT': 'A',\n",
    " 'GCC': 'A',\n",
    " 'GCA': 'A',\n",
    " 'GCG': 'A',\n",
    " 'GAT': 'D',\n",
    " 'GAC': 'D',\n",
    " 'GAA': 'E',\n",
    " 'GAG': 'E',\n",
    " 'GGT': 'G',\n",
    " 'GGC': 'G',\n",
    " 'GGA': 'G',\n",
    " 'GGG': 'G'}\n",
    "\n",
    "tRNA_to_codon_table = dict()\n",
    "for key in DNA_to_codon_table:\n",
    "    aa_id = DNA_to_codon_table[key]\n",
    "    aa_id = seq3(aa_id)\n",
    "    key_tRNA = Seq.transcribe(key)\n",
    "    tRNA_to_codon_table[key_tRNA] = aa_id\n",
    "    \n",
    "\n",
    "tRNA_to_codon_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_key(my_dict, val): \n",
    "    key_list = []\n",
    "    for key, value in my_dict.items(): \n",
    "         if val == value: \n",
    "                key_list.append(key)\n",
    "    return key_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trna_to_codon = dict()\n",
    "for tRNA_PFrame in bsub.tRNAs.instances:\n",
    "    tRNA_data = pc.PToolsFrame.PFrame.get_frame_data(tRNA_PFrame)\n",
    "    \n",
    "    tRNA_id = str(tRNA_data.frameid)\n",
    "    tRNA_id = tRNA_id.replace('|','')\n",
    "    tRNA_id = tRNA_id.replace('-tRNA','')\n",
    "    tRNA_id = tRNA_id.replace('TRNA','tRNA')\n",
    "    \n",
    "    aa_id = tRNA_data.common_name\n",
    "    aa_id = aa_id[len(aa_id)-3:len(aa_id)]\n",
    "    \n",
    "    codon_list = get_key(tRNA_to_codon_table, aa_id)\n",
    "    \n",
    "    trna_to_codon[tRNA_id] = codon_list\n",
    "    \n",
    "trna_to_codon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tRNA_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaved methionine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Methionine cleaved feature dictionary\n",
    "met_cleaved_features = []\n",
    "for instance in bsub.amino_acid_sites.instances:\n",
    "    instance_data = pc.PToolsFrame.PFrame.get_frame_data(instance)\n",
    "    try :\n",
    "        if instance.comment[0] == 'UniProt: Removed.':\n",
    "            met_cleaved_features.append(instance.frameid)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "met_cleaved_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "met_cleaved_prots = []\n",
    "for protein in bsub.proteins.instances:\n",
    "    protein_id = frameid_to_str(protein.frameid)\n",
    "    gene_id = protein_id.split('-MONOMER')[0]\n",
    "    try:\n",
    "        features = protein.features\n",
    "        if list(set(features) & set(met_cleaved_features)):\n",
    "            met_cleaved_prots.append(gene_id)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string = ''\n",
    "i = 0\n",
    "for prot in met_cleaved_prots:\n",
    "    i = i + 1\n",
    "    string = string + \"'\" + prot + \"'\" + ','\n",
    "    if not i%5:\n",
    "        string = string + '\\n'\n",
    "print string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## peptide_compartment_and_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "gb_file = SeqIO.read('NC_000964.gb', 'gb')\n",
    "element_types={'CDS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include_locations = ['|CCI-PM-BAC-POS-GP|','|CCI-CW-BAC-POS-GP|','|CCI-EXTRACELLULAR-GP|']\n",
    "monomer_location_dict = {}\n",
    "for protein in bsub.proteins.instances:\n",
    "    protein_id = frameid_to_str(protein.frameid)\n",
    "    protein_data = pc.PToolsFrame.PFrame.get_frame_data(protein)\n",
    "    locations = protein_data.locations\n",
    "    if locations and len(set(locations) & set(include_locations)):\n",
    "        protein_id = protein_id.split('-MONOMER')[0]\n",
    "        monomer_location_dict[protein_id] = []\n",
    "        if '|CCI-PM-BAC-POS-GP|' in locations:\n",
    "            monomer_location_dict[protein_id].append('PM')\n",
    "        if '|CCI-CW-BAC-POS-GP|' in locations:\n",
    "            monomer_location_dict[protein_id].append('CW')\n",
    "        if '|CCI-EXTRACELLULAR-GP|' in locations:\n",
    "            monomer_location_dict[protein_id].append('EX')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create FASTA file with AA sequences of membrane monomers\n",
    "FASTA_file = 'membrane_genes.faa'\n",
    "file = open(FASTA_file,'w')\n",
    "for feature in gb_file.features:\n",
    "    if feature.type not in element_types:\n",
    "        continue\n",
    "    try:\n",
    "        gene_id = feature.qualifiers['old_locus_tag'][0]\n",
    "    except:\n",
    "        gene_id = feature.qualifiers['locus_tag'][0]\n",
    "    if gene_id in monomer_location_dict.keys():\n",
    "        try:\n",
    "            seq = feature.qualifiers['translation'][0]\n",
    "            file.write('>>'+gene_id+'\\n')\n",
    "            file.write(seq+'\\n')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create FASTA file with AA sequences of membrane monomers\n",
    "FASTA_file = 'secreted_genes.faa'\n",
    "file = open(FASTA_file,'w')\n",
    "for feature in gb_file.features:\n",
    "    if feature.type not in element_types:\n",
    "        continue\n",
    "    try:\n",
    "        gene_id = feature.qualifiers['old_locus_tag'][0]\n",
    "    except:\n",
    "        gene_id = feature.qualifiers['locus_tag'][0]\n",
    "    if gene_id in monomer_location_dict.keys() and 'EX' in monomer_location_dict[gene_id]:\n",
    "        try:\n",
    "            seq = feature.qualifiers['translation'][0]\n",
    "            file.write('>>'+gene_id+'\\n')\n",
    "            file.write(seq+'\\n')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## FASTA_file is processed using SignalP 5.0 http://www.cbs.dtu.dk/services/SignalP/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pathways_file = open('output_protein_type.txt')\n",
    "data = pathways_file.read()\n",
    "parsed_data = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "protein_translocation_pathway_dict = {}\n",
    "for instance in parsed_data:\n",
    "    gene_id = instance[1:9]\n",
    "    if 'BSU' in gene_id:\n",
    "        if 'Tat' in instance:\n",
    "            protein_translocation_pathway_dict[gene_id] = 't'\n",
    "            print(instance)\n",
    "        elif 'Sec' in instance:\n",
    "            protein_translocation_pathway_dict[gene_id] = 's'\n",
    "        else:\n",
    "            protein_translocation_pathway_dict[gene_id] = 's' # Default Sec-pathway, since its the major one\n",
    "            \n",
    "## Note: ABC transport has not been included yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'peptide_compartment_and_pathways.txt'\n",
    "file = open(filename,'w')\n",
    "\n",
    "file.write('Complex' + '\\t' + 'Complex_compartment' + '\\t' + 'Protein' + '\\t' + 'Protein_compartment' +\n",
    "           '\\t' + 'translocase_pathway''\\n')\n",
    "\n",
    "for protein_id in protein_complexes_dict.keys():\n",
    "    genes_of_cplx = protein_complexes_dict[protein_id]\n",
    "    if len(set(genes_of_cplx) & set(monomer_location_dict.keys())) == len(genes_of_cplx):\n",
    "        for gene in genes_of_cplx:\n",
    "            try:\n",
    "                stoich  = str(int(bsub_stoich_dict[protein_id][gene]))\n",
    "            except:\n",
    "                stoich = '1'\n",
    "            try:\n",
    "                transloc_pathway = protein_translocation_pathway_dict[gene]\n",
    "            except:\n",
    "                transloc_pathway = 's'\n",
    "            \n",
    "            if 'PM' in monomer_location_dict[gene]:\n",
    "                location = 'Inner_Membrane'\n",
    "            elif 'CW' in monomer_location_dict[gene]:\n",
    "                location = 'Outer_Membrane'\n",
    "            #if 'EX' in monomer_location_dict[gene]:\n",
    "            #    location = 'Secreted'\n",
    "                \n",
    "            file.write(protein_id + '\\t' + location + '\\t' + gene + '(' + stoich + ')' + '\\t' +\n",
    "                               location + '\\t' + transloc_pathway + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define Models\n",
    "ijo_directory = './iYO844.json'\n",
    "\n",
    "ijo = cobra.io.load_json_model(ijo_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "central_CE = ['carbohydrate','energy']\n",
    "central_AFN = ['amino_acid','fatty_acid','lipid','nucleotide']\n",
    "intermediate = ['cofactor','coenzymes','prosthetic_groups']\n",
    "\n",
    "def check_if_contained(ref_list,string):\n",
    "    c = 0\n",
    "    for i in ref_list:\n",
    "        if i in string.lower():\n",
    "            c = 1\n",
    "            break\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "central_CE_list = []\n",
    "central_AFN_list = []\n",
    "intermediate_list = []\n",
    "secondary_list = []\n",
    "\n",
    "classification_dict = dict()\n",
    "\n",
    "delimiters = ' and ',' or '\n",
    "regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "for rxn in ijo.reactions:\n",
    "    if rxn.gene_reaction_rule:\n",
    "        rule = rxn.gene_reaction_rule\n",
    "        rule_list = re.split(regexPattern,rule)\n",
    "        if check_if_contained(central_CE,rxn.subsystem):\n",
    "            for gene in rule_list:\n",
    "                gene = gene.replace('(','')\n",
    "                gene = gene.replace(')','')\n",
    "                central_CE_list.append(gene)\n",
    "                classification_dict[gene] = 'central_CE'\n",
    "        elif check_if_contained(central_AFN,rxn.subsystem):\n",
    "            for gene in rule_list:\n",
    "                gene = gene.replace('(','')\n",
    "                gene = gene.replace(')','')\n",
    "                classification_dict[gene] = 'central_AFN'\n",
    "                central_AFN_list.append(gene)\n",
    "        elif check_if_contained(intermediate,rxn.subsystem):\n",
    "            for gene in rule_list:\n",
    "                gene = gene.replace('(','')\n",
    "                gene = gene.replace(')','')\n",
    "                classification_dict[gene] = 'intermediate'\n",
    "                intermediate_list.append(gene)\n",
    "        else:\n",
    "            for gene in rule_list:\n",
    "                gene = gene.replace('(','')\n",
    "                gene = gene.replace(')','')\n",
    "                classification_dict[gene] = 'secondary'\n",
    "                secondary_list.append(gene)\n",
    "central_CE_list = list(set(central_CE_list))\n",
    "central_AFN_list = list(set(central_AFN_list))\n",
    "intermediate_list = list(set(intermediate_list))\n",
    "secondary_list = list(set(secondary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'reaction_median_keffs.txt'\n",
    "\n",
    "subsystem_keffs_dict = {'central_CE':'79','central_AFN':'18','intermidiate':'5.2','secondary':'2.5'}\n",
    "\n",
    "file = open(filename,'w')\n",
    "\n",
    "reaction_versions = ['REV','FWD']\n",
    "\n",
    "for protein in bsub.proteins.instances:\n",
    "    protein_id = frameid_to_str(protein.frameid)\n",
    "    protein_data = pc.PToolsFrame.PFrame.get_frame_data(protein)\n",
    "    \n",
    "    protein_type = []\n",
    "    genes_of_cplx = pc.PGDB.genes_of_protein(bsub,protein)\n",
    "    if genes_of_cplx:\n",
    "        protein_type = []\n",
    "        for gene in genes_of_cplx:\n",
    "            try:\n",
    "                gene_id = frameid_to_str(gene)\n",
    "                protein_type.append(classification_dict[gene_id])\n",
    "            except:\n",
    "                continue\n",
    "        protein_type = list(set(protein_type))\n",
    "        if not protein_type:\n",
    "            protein_type = ['unknown']\n",
    "        try:\n",
    "            protein_keff = subsystem_keffs_dict[protein_type[0]]\n",
    "        except:\n",
    "            protein_keff = '65'\n",
    "    try:\n",
    "        if protein_id in cplx_cofactor_dict.keys():\n",
    "            string = protein_id\n",
    "            for cofactor in cplx_cofactor_dict[protein_id].keys():\n",
    "                stoich = int(cplx_cofactor_dict[protein_id][cofactor])\n",
    "                if stoich == 1:\n",
    "                    string = string + '_mod_' + cofactor\n",
    "                else:\n",
    "                    string = string + '_mod_' + str(stoich) + ':' + cofactor\n",
    "            protein_id = string\n",
    "        reaction_id = enz_rxn_assoc_dict[protein_id]\n",
    "        for ver in reaction_versions:\n",
    "            real_reaction_id = reaction_id + '_' + ver + '_' + protein_id\n",
    "            file.write(real_reaction_id + '\\t' + protein_id + '\\t' + protein_keff + '\\n')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save modified m_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cobra.io.save_json_model(m_model,'iYO844_mod.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for protein in bsub.tRNAs.instances:\n",
    "    protein_id = frameid_to_str(protein.frameid)\n",
    "    protein_data = pc.PToolsFrame.PFrame.get_frame_data(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for protein in bsub.polypeptides.instances:\n",
    "    protein_id = frameid_to_str(protein.frameid)\n",
    "    protein_data = pc.PToolsFrame.PFrame.get_frame_data(protein)\n",
    "    if protein_id == 'BSU02850-MONOMER':\n",
    "        test = protein_data\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for protein in bsub.genes:\n",
    "    protein_id = frameid_to_str(protein.frameid)\n",
    "    protein_data = pc.PToolsFrame.PFrame.get_frame_data(protein)\n",
    "    if protein_id == ''\n",
    "    print(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for protein in ecoli.proteins.instances:\n",
    "    protein_id = frameid_to_str(protein.frameid)\n",
    "    protein_data = pc.PToolsFrame.PFrame.get_frame_data(protein)\n",
    "    if protein_id == 'ABS-2_CPLX':\n",
    "        test = protein_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cplx_to_cplx_dict['CPLX8J2-181']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_cofactors = []\n",
    "for cplx in cplx_cofactor_dict.keys():\n",
    "    for cofactor in cplx_cofactor_dict[cplx].keys():\n",
    "        all_cofactors.append(cofactor)\n",
    "all_cofactors = list(set(all_cofactors))\n",
    "all_cofactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
